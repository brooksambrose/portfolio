
@article{Palla2007Quantifying,
	title = {Quantifying social group evolution},
	volume = {446},
	copyright = {2007 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature05670},
	doi = {10.1038/nature05670},
	abstract = {The rich set of interactions between individuals in society1,2,3,4,5,6,7 results in complex community structure, capturing highly connected circles of friends, families or professional cliques in a social network3,7,8,9,10. Thanks to frequent changes in the activity and communication patterns of individuals, the associated social and communication network is subject to constant evolution7,11,12,13,14,15,16. Our knowledge of the mechanisms governing the underlying community dynamics is limited, but is essential for a deeper understanding of the development and self-optimization of society as a whole17,18,19,20,21,22. We have developed an algorithm based on clique percolation23,24 that allows us to investigate the time dependence of overlapping communities on a large scale, and thus uncover basic relationships characterizing community evolution. Our focus is on networks capturing the collaboration between scientists and the calls between mobile phone users. We find that large groups persist for longer if they are capable of dynamically altering their membership, suggesting that an ability to change the group composition results in better adaptability. The behaviour of small groups displays the opposite tendency—the condition for stability is that their composition remains unchanged. We also show that knowledge of the time commitment of members to a given community can be used for estimating the community’s lifetime. These findings offer insight into the fundamental differences between the dynamics of small groups and large institutions.},
	language = {en},
	number = {7136},
	urldate = {2018-11-05},
	journal = {Nature},
	author = {Palla, Gergely and Barabási, Albert-László and Vicsek, Tamás},
	month = apr,
	year = {2007},
	note = {Citation Key: Palla2007Quantifying},
	pages = {664--667}
}

@article{Gregori2013Parallel,
	title = {Parallel {K}-{Clique} {Community} {Detection} on {Large}-{Scale} {Networks}},
	volume = {24},
	issn = {1045-9219},
	url = {http://ieeexplore.ieee.org/document/6249683/},
	doi = {10.1109/TPDS.2012.229},
	number = {8},
	urldate = {2018-11-05},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Gregori, Enrico and Lenzini, Luciano and Mainardi, Simone},
	month = aug,
	year = {2013},
	note = {Citation Key: Gregori2013Parallel},
	pages = {1651--1660}
}

@article{Blondel2008Fast,
	title = {Fast unfolding of communities in large networks},
	url = {https://arxiv.org/abs/0803.0476},
	doi = {10.1088/1742-5468/2008/10/P10008},
	language = {en},
	urldate = {2018-11-05},
	author = {Blondel, Vincent D. and Guillaume, Jean-Loup and Lambiotte, Renaud and Lefebvre, Etienne},
	month = mar,
	year = {2008},
	note = {Citation Key: Blondel2008Fast}
}

@article{Krivitsky2008Fitting,
	title = {Fitting {Position} {Latent} {Cluster} {Models} for {Social} {Networks} with latentnet},
	volume = {24},
	issn = {1548-7660},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5552185/},
	doi = {10.18637/jss.v024.i05},
	abstract = {latentnet is a package to fit and evaluate statistical latent position and cluster models for networks.  suggested an approach to modeling networks based on positing the existence of an latent space of characteristics of the actors. Relationships form as a function of distances between these characteristics as well as functions of observed dyadic level covariates. In latentnet social distances are represented in a Euclidean space. It also includes a variant of the extension of the latent position model to allow for clustering of the positions developed in ., The package implements Bayesian inference for the models based on an Markov chain Monte Carlo algorithm. It can also compute maximum likelihood estimates for the latent position model and a two-stage maximum likelihood method for the latent position cluster model. For latent position cluster models, the package provides a Bayesian way of assessing how many groups there are, and thus whether or not there is any clustering (since if the preferred number of groups is 1, there is little evidence for clustering). It also estimates which cluster each actor belongs to. These estimates are probabilistic, and provide the probability of each actor belonging to each cluster. It computes four types of point estimates for the coefficients and positions: maximum likelihood estimate, posterior mean, posterior mode and the estimator which minimizes Kullback-Leibler divergence from the posterior. You can assess the goodness-of-fit of the model via posterior predictive checks. It has a function to simulate networks from a latent position or latent position cluster model.},
	urldate = {2018-11-04},
	journal = {Journal of statistical software},
	author = {Krivitsky, Pavel N. and Handcock, Mark S.},
	month = feb,
	year = {2008},
	pmid = {28804272},
	pmcid = {PMC5552185},
	note = {Citation Key: Krivitsky2008Fitting}
}

@misc{JSTOR2018Title,
	title = {Title {Lists}},
	url = {http://support.jstor.org/hc/en-us/articles/115007466248-JSTOR-Title-Lists},
	abstract = {What's in this article:

Quick Links to Common Collections
About JSTOR Title Lists
All Title Lists


Quick Links
Immediately below are links to the KBART files of some of the most commonly download...},
	language = {en-US},
	urldate = {2018-10-30},
	journal = {JSTOR Support Home},
	author = {JSTOR},
	month = oct,
	year = {2018},
	note = {Citation Key: JSTOR2018Title}
}

@incollection{Schreibman2014NonConsumptive,
	address = {London},
	title = {Non-{Consumptive} {Reading}},
	isbn = {978-1-137-42970-4},
	url = {https://doi.org/10.1057/9781137429704_11},
	abstract = {For the last decade or so we have been talking about the new tools and methodologies of digital humanities creating a paradigm shift in the ways in which we conduct literary research. From the mid-1990s to the early 2000s, the digital archive or thematic research collection was going to revolutionize the ways in which we studied primary sources. By bringing together multiple print editions (as in the Whitman Archive) or multiple printings of an author's works (both images and texts, as in the Blake Archive), or providing a tool to display multiple versions of an author's manuscript drafts of poetry (as in the Versioning Machine), we expected to open up wholly new ways of engaging with text.},
	booktitle = {From {Literature} to {Cultural} {Literacy}},
	publisher = {Palgrave Macmillan UK},
	author = {Schreibman, Susan},
	editor = {Segal, Naomi and Koleva, Daniela},
	year = {2014},
	doi = {10.1057/9781137429704_11},
	note = {Citation Key: Schreibman2014NonConsumptive},
	pages = {148--165}
}

@book{Lloyd1762Poems,
	title = {Poems},
	language = {en},
	publisher = {author},
	author = {Lloyd, Robert},
	year = {1762},
	note = {Google-Books-ID: t71IAAAAMAAJ
Citation Key: Lloyd1762Poems}
}

@book{Aesop2003Complete,
	title = {The {Complete} {Fables}},
	isbn = {978-0-14-191578-4},
	abstract = {Aesop was probably a prisoner of war, sold into slavery in the early sixth century BC, who represented his masters in court and negotiations, and relied on animal stories to put across his key points. All these fables, full of humour, insight and savage wit, as well as many fascinating glimpses of ordinary life, have now been brought together for the first time in this definitive and fully annotated modern edition.},
	language = {en},
	publisher = {Penguin UK},
	author = {{Aesop}},
	month = may,
	year = {2003},
	note = {Citation Key: Aesop2003Complete},
	keywords = {Fiction / Classics, Literary Collections / Ancient \& Classical, Literary Criticism / Ancient \& Classical}
}

@book{Johnson1802Works,
	title = {The {Works} of the {Poets} of {Great} {Britain} and {Ireland}: {With} {Prefaces}, {Biographical} and {Critical}. {By} {Samuel} {Johnson}. ...},
	shorttitle = {The {Works} of the {Poets} of {Great} {Britain} and {Ireland}},
	language = {en},
	publisher = {J. Moore},
	author = {Johnson, Samuel},
	year = {1802},
	note = {Google-Books-ID: flRaTCrSYkoC
Citation Key: Johnson1802Works}
}

@book{Berlin1953Hedgehog,
	address = {London},
	title = {The {Hedgehog} and the {Fox}: {An} {Essay} on {Tolstoy}'s {View} of {History}},
	shorttitle = {The hedgehog and the fox},
	language = {English},
	publisher = {Weidenfeld \& Nicolson},
	author = {Berlin, Isaiah},
	year = {1953},
	note = {OCLC: 10872907
Citation Key: Berlin1953Hedgehog}
}

@article{Gerlach2018network,
	title = {A network approach to topic models},
	volume = {4},
	copyright = {Copyright © 2018 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC).. This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial license, which permits use, distribution, and reproduction in any medium, so long as the resultant use is not for commercial advantage and provided the original work is properly cited.},
	issn = {2375-2548},
	url = {http://advances.sciencemag.org/content/4/7/eaaq1360},
	doi = {10.1126/sciadv.aaq1360},
	abstract = {{\textless}p{\textgreater}One of the main computational and scientific challenges in the modern age is to extract useful information from unstructured texts. Topic models are one popular machine-learning approach that infers the latent topical structure of a collection of documents. Despite their success—particularly of the most widely used variant called latent Dirichlet allocation (LDA)—and numerous applications in sociology, history, and linguistics, topic models are known to suffer from severe conceptual and practical problems, for example, a lack of justification for the Bayesian priors, discrepancies with statistical properties of real texts, and the inability to properly choose the number of topics. We obtain a fresh view of the problem of identifying topical structures by relating it to the problem of finding communities in complex networks. We achieve this by representing text corpora as bipartite networks of documents and words. By adapting existing community-detection methods (using a stochastic block model (SBM) with nonparametric priors), we obtain a more versatile and principled framework for topic modeling (for example, it automatically detects the number of topics and hierarchically clusters both the words and documents). The analysis of artificial and real corpora demonstrates that our SBM approach leads to better topic models than LDA in terms of statistical model selection. Our work shows how to formally relate methods from community detection and topic modeling, opening the possibility of cross-fertilization between these two fields.{\textless}/p{\textgreater}},
	language = {en},
	number = {7},
	urldate = {2018-10-21},
	journal = {Science Advances},
	author = {Gerlach, Martin and Peixoto, Tiago P. and Altmann, Eduardo G.},
	month = jul,
	year = {2018},
	note = {Citation Key: Gerlach2018network},
	pages = {eaaq1360}
}

@book{Patterson2001Social,
	address = {Oxford; New York},
	title = {A {Social} {History} of {Anthropology} in the {United} {States}},
	isbn = {1-85973-489-8 978-1-85973-489-6 1-85973-494-4 978-1-85973-494-0},
	abstract = {"In part due to the recent Yanomami controversy, which has rocked anthropology to its very core, there is renewed interest in the discipline's history and intellectual roots, especially amongst anthropologists themselves. The cutting edge of anthropological research today is a product of earlier questions and answers, previous ambitions, preoccupations and adventures, stretching back one hundred years or more. This book is the first comprehensive history of American anthropology. Crucially, Patterson relates the development of anthropology in the United States to wider historical currents in society." "This book will be essential reading for anyone interested in understanding the roots and reasons behind American anthropology at the turn of the twenty-first century. Intellectual historians, social scientists, and anyone intrigued by the growth and development of institutional politics and practices should read this book."--Jacket.},
	language = {English},
	publisher = {Berg},
	author = {Patterson, Thomas C},
	year = {2001},
	note = {OCLC: 48551832
Citation Key: Patterson2001Social}
}

@book{Calhoun2007Sociology,
	address = {Chicago},
	title = {Sociology in {America}: {A} {History}},
	url = {http://books.google.com/books?hl=en&lr=&id=_TGlJn8iEikC&oi=fnd&pg=PA1&dq=How+facts+travel+The+model+systems+of+sociology&ots=RcEP40jjhS&sig=zXZ5mLlOCdDeNt_0jQFurm8CVdA},
	publisher = {University of Chicago Press},
	author = {Calhoun, Craig},
	editor = {Calhoun, Craig},
	year = {2007},
	note = {Citation Key: Calhoun2007Sociology}
}

@article{Arora2018Learning,
	title = {Learning {Topic} {Models} -- {Provably} and {Efficiently}},
	volume = {61},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/3186262},
	doi = {10.1145/3186262},
	number = {4},
	journal = {Commun. ACM},
	author = {Arora, Sanjeev and Ge, Rong and Halpern, Yoni and Mimno, David and Moitra, Ankur and Sontag, David and Wu, Yichen and Zhu, Michael},
	month = mar,
	year = {2018},
	note = {Citation Key: Arora2018Learning},
	pages = {85--93}
}

@article{Baumer2017Comparing,
	title = {Comparing grounded theory and topic modeling: {Extreme} divergence or unlikely convergence?},
	volume = {68},
	copyright = {© 2017 ASIS\&T},
	issn = {2330-1643},
	shorttitle = {Comparing grounded theory and topic modeling},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.23786},
	doi = {10.1002/asi.23786},
	abstract = {Researchers in information science and related areas have developed various methods for analyzing textual data, such as survey responses. This article describes the application of analysis methods from two distinct fields, one method from interpretive social science and one method from statistical machine learning, to the same survey data. The results show that the two analyses produce some similar and some complementary insights about the phenomenon of interest, in this case, nonuse of social media. We compare both the processes of conducting these analyses and the results they produce to derive insights about each method's unique advantages and drawbacks, as well as the broader roles that these methods play in the respective fields where they are often used. These insights allow us to make more informed decisions about the tradeoffs in choosing different methods for analyzing textual data. Furthermore, this comparison suggests ways that such methods might be combined in novel and compelling ways.},
	language = {en},
	number = {6},
	urldate = {2018-10-16},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Baumer, Eric P. S. and Mimno, David and Guha, Shion and Quan, Emily and Gay, Geri K.},
	month = jun,
	year = {2017},
	note = {Citation Key: Baumer2017Comparing},
	pages = {1397--1410}
}

@article{Wattenberg2016How,
	title = {How to {Use} t-{SNE} {Effectively}},
	volume = {1},
	issn = {2476-0757},
	url = {http://distill.pub/2016/misread-tsne},
	doi = {10.23915/distill.00002},
	abstract = {Although extremely useful for visualizing high-dimensional data, t-SNE plots can sometimes be mysterious or misleading.},
	language = {en},
	number = {10},
	urldate = {2018-10-16},
	journal = {Distill},
	author = {Wattenberg, Martin and Viégas, Fernanda and Johnson, Ian},
	month = oct,
	year = {2016},
	note = {Citation Key: Wattenberg2016How},
	pages = {e2}
}

@article{Young2018Deep,
	title = {Deep {Super} {Learner}: {A} {Deep} {Ensemble} for {Classification} {Problems}},
	shorttitle = {Deep {Super} {Learner}},
	url = {https://arxiv.org/abs/1803.02323},
	language = {en},
	urldate = {2018-09-26},
	author = {Young, Steven and Abdou, Tamer and Bener, Ayse},
	month = mar,
	year = {2018},
	note = {Citation Key: Young2018Deep}
}

@book{Austin1962How,
	title = {How to {Do} {Things} with {Words}},
	language = {en},
	publisher = {Clarendon Press},
	author = {Austin, John L.},
	year = {1962},
	note = {Google-Books-ID: qO7WAAAAMAAJ
Citation Key: Austin1962How}
}

@inproceedings{Mimno2007Organizing,
	address = {New York, NY, USA},
	series = {{JCDL} '07},
	title = {Organizing the {OCA}: {Learning} {Faceted} {Subjects} from a {Library} of {Digital} {Books}},
	isbn = {978-1-59593-644-8},
	shorttitle = {Organizing the {OCA}},
	url = {http://doi.acm.org/10.1145/1255175.1255249},
	doi = {10.1145/1255175.1255249},
	abstract = {Large scale library digitization projects such as the Open Content Alliance are producing vast quantities of text, but little has been done to organize this data. Subject headings inherited from card catalogs are useful but limited, while full-text indexing is most appropriate for readers who already know exactly what they want. Statistical topic models provide a complementary function. These models can identify semantically coherent "topics" that are easily recognizable and meaningful to humans, but they have been too computationally intensive to run on library-scale corpora. This paper presents DCM-LDA, a topic model based on Dirichlet Compound Multinomial distributions. This model is simultaneously better able to represent observed properties of text and more scalable to extremely large text collections. We train individual topic models for each book based on the cooccurrence of words within pages. We then cluster topics across books. The resulting topical clusters can be interpreted as subject facets, allowing readers to browse the topics of a collection quickly, find relevant books using topically expanded keyword searches, and explore topical relationships between books. We demonstrate this method finding topics on a corpus of 1.49 billion words from 42,000 books in less than 20 hours, and it easily could scale well beyond this.},
	urldate = {2018-09-10},
	booktitle = {Proceedings of the 7th {ACM}/{IEEE}-{CS} {Joint} {Conference} on {Digital} {Libraries}},
	publisher = {ACM},
	author = {Mimno, David and McCallum, Andrew},
	year = {2007},
	note = {Citation Key: Mimno2007Organizing},
	keywords = {classification, topic models},
	pages = {376--385}
}

@inproceedings{Hall2008Studying,
	address = {Stroudsburg, PA, USA},
	series = {{EMNLP} '08},
	title = {Studying the {History} of {Ideas} {Using} {Topic} {Models}},
	url = {http://dl.acm.org/citation.cfm?id=1613715.1613763},
	abstract = {How can the development of ideas in a scientific field be studied over time? We apply unsupervised topic modeling to the ACL Anthology to analyze historical trends in the field of Computational Linguistics from 1978 to 2006. We induce topic clusters using Latent Dirichlet Allocation, and examine the strength of each topic over time. Our methods find trends in the field including the rise of probabilistic methods starting in 1988, a steady increase in applications, and a sharp decline of research in semantics and understanding between 1978 and 2001, possibly rising again after 2001. We also introduce a model of the diversity of ideas, topic entropy, using it to show that COLING is a more diverse conference than ACL, but that both conferences as well as EMNLP are becoming broader over time. Finally, we apply Jensen-Shannon divergence of topic distributions to show that all three conferences are converging in the topics they cover.},
	urldate = {2018-09-10},
	booktitle = {Proceedings of the {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Hall, David and Jurafsky, Daniel and Manning, Christopher D.},
	year = {2008},
	note = {Citation Key: Hall2008Studying},
	pages = {363--371}
}

@article{Blei2007correlated,
	title = {A correlated topic model of {Science}},
	volume = {1},
	issn = {1932-6157},
	url = {http://arxiv.org/abs/0708.3601},
	doi = {10.1214/07-AOAS114},
	abstract = {Topic models, such as latent Dirichlet allocation (LDA), can be useful tools for the statistical analysis of document collections and other discrete data. The LDA model assumes that the words of each document arise from a mixture of topics, each of which is a distribution over the vocabulary. A limitation of LDA is the inability to model topic correlation even though, for example, a document about genetics is more likely to also be about disease than X-ray astronomy. This limitation stems from the use of the Dirichlet distribution to model the variability among the topic proportions. In this paper we develop the correlated topic model (CTM), where the topic proportions exhibit correlation via the logistic normal distribution [J. Roy. Statist. Soc. Ser. B 44 (1982) 139--177]. We derive a fast variational inference algorithm for approximate posterior inference in this model, which is complicated by the fact that the logistic normal is not conjugate to the multinomial. We apply the CTM to the articles from Science published from 1990--1999, a data set that comprises 57M words. The CTM gives a better fit of the data than LDA, and we demonstrate its use as an exploratory tool of large document collections.},
	number = {1},
	urldate = {2018-09-10},
	journal = {The Annals of Applied Statistics},
	author = {Blei, David M. and Lafferty, John D.},
	month = jun,
	year = {2007},
	note = {arXiv: 0708.3601
Citation Key: Blei2007correlated},
	keywords = {Statistics - Applications},
	pages = {17--35}
}

@inproceedings{Newman2006Analyzing,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Analyzing {Entities} and {Topics} in {News} {Articles} {Using} {Statistical} {Topic} {Models}},
	isbn = {978-3-540-34479-7},
	abstract = {Statistical language models can learn relationships between topics discussed in a document collection and persons, organizations and places mentioned in each document. We present a novel combination of statistical topic models and named-entity recognizers to jointly analyze entities mentioned (persons, organizations and places) and topics discussed in a collection of 330,000 New York Times news articles. We demonstrate an analytic framework which automatically extracts from a large collection: topics; topic trends; and topics that relate entities.},
	language = {en},
	booktitle = {Intelligence and {Security} {Informatics}},
	publisher = {Springer Berlin Heidelberg},
	author = {Newman, David and Chemudugunta, Chaitanya and Smyth, Padhraic and Steyvers, Mark},
	editor = {Mehrotra, Sharad and Zeng, Daniel D. and Chen, Hsinchun and Thuraisingham, Bhavani and Wang, Fei-Yue},
	year = {2006},
	note = {Citation Key: Newman2006Analyzing},
	keywords = {Latent Dirichlet Allocation, Latent Semantic Analysis, Latent Semantic Indexing, News Article, Topic Model},
	pages = {93--104}
}

@incollection{Grimmer2016Measuring,
	address = {New York, NY},
	edition = {Reprint edition},
	series = {Analytical {Methods} for {Social} {Research}},
	title = {Measuring {Representational} {Style} in the {House}: {The} {Tea} {Party}, {Obama}, and {Legislators}’ {Changing} {Expressed} {Priorities}},
	isbn = {978-1-107-51841-4},
	url = {https://www.cambridge.org/core/books/computational-social-science/measuring-representational-style-in-the-house-the-tea-party-obama-and-legislators-changing-expressed-priorities/F796451CE2D672F7479498CF82ADEA54},
	abstract = {Quantitative research in social science research is changing rapidly. Researchers have vast and complex arrays of data with which to work: we have incredible tools to sift through the data and recognize patterns in that data; there are now many sophisticated models that we can use to make sense of those patterns; and we have extremely powerful computational systems that help us accomplish these tasks quickly. This book focuses on some of the extraordinary work being conducted in computational social science - in academia, government, and the private sector - while highlighting current trends, challenges, and new directions. Thus, Computational Social Science showcases the innovative methodological tools being developed and applied by leading researchers in this new field. The book shows how academics and the private sector are using many of these tools to solve problems in social science and public policy.},
	language = {English},
	urldate = {2016-09-22},
	booktitle = {Computational {Social} {Science}: {Discovery} and {Prediction}},
	publisher = {Cambridge University Press},
	author = {Grimmer, Justin},
	editor = {Alvarez, R. Michael},
	month = mar,
	year = {2016},
	note = {Citation Key: Grimmer2016Measuring},
	pages = {225--245}
}

@book{JOCKERS2013Macroanalysis,
	title = {Macroanalysis: {Digital} {Methods} and {Literary} {History}},
	isbn = {978-0-252-03752-8},
	shorttitle = {Macroanalysis},
	url = {https://www.jstor.org/stable/10.5406/j.ctt2jcc3m},
	abstract = {In this volume, Matthew L. Jockers introduces readers to large-scale literary computing and the revolutionary potential of macroanalysis--a new approach to the study of the literary record designed for probing the digital-textual world as it exists today, in digital form and in large quantities. Using computational analysis to retrieve key words, phrases, and linguistic patterns across thousands of texts in digital libraries, researchers can draw conclusions based on quantifiable evidence regarding how literary trends are employed over time, across periods, within regions, or within demographic groups, as well as how cultural, historical, and societal linkages may bind individual authors, texts, and genres into an aggregate literary culture. Moving beyond the limitations of literary interpretation based on the close-reading of individual works, Jockers describes how this new method of studying large collections of digital material can help us to better understand and contextualize the individual works within those collections.},
	urldate = {2018-09-06},
	publisher = {University of Illinois Press},
	author = {JOCKERS, MATTHEW L.},
	year = {2013},
	note = {Citation Key: JOCKERS2013Macroanalysis}
}

@book{Luhmann2002Theories,
	title = {Theories of {Distinction}: {Redescribing} the {Descriptions} of {Modernity}},
	isbn = {978-0-8047-4123-1},
	shorttitle = {Theories of {Distinction}},
	abstract = {The essays in this volume by Germany\&\#39;s leading social theorist of the late twentieth century formulate what he considered to be the preconditions for an adequate theory of modern society.  The first two essays deal with the modern European philosophical and scientific tradition, notably the ogy of Edmund Husserl. The next four essays concern the crucial notion of observation as defined by Luhmann. They examine the history of paradox as a logical problem and as a historically conditioned feature of rhetoric; deconstruct the thinking of Jacques Derrida, especially his language-centered allegiances; discuss the usefulness of Spencer Brown\&\#39;s Laws of Form; and assess the consequences of observation and paradox for epistemology.  The following essays present Luhmann\&\#39;s theory of communication and his articulation of the difference between thought and communication, a difference that makes clear one of Luhmann\&\#39;s most radical and controversial theses, that the individual not only does not form the basic element of society but is excluded from it altogether, situated instead in the environment of the social system. The book concludes with a polemic against the critical thought of the Frankfurt School of postwar German social thought.},
	language = {en},
	publisher = {Stanford University Press},
	author = {Luhmann, Niklas and Rasch, William},
	year = {2002},
	note = {Google-Books-ID: L0G2bwV9VMMC
Citation Key: Luhmann2002Theories},
	keywords = {Social Science / Sociology / General}
}

@article{DiMaggio2013Exploiting,
	series = {Topic {Models} and the {Cultural} {Sciences}},
	title = {Exploiting affinities between topic modeling and the sociological perspective on culture: {Application} to newspaper coverage of {U}.{S}. government arts funding},
	volume = {41},
	issn = {0304-422X},
	shorttitle = {Exploiting affinities between topic modeling and the sociological perspective on culture},
	url = {http://www.sciencedirect.com/science/article/pii/S0304422X13000661},
	doi = {10.1016/j.poetic.2013.08.004},
	abstract = {Topic modeling provides a valuable method for identifying the linguistic contexts that surround social institutions or policy domains. This article uses Latent Dirichlet Allocation (LDA) to analyze how one such policy domain, government assistance to artists and arts organizations, was framed in almost 8000 articles. These comprised all articles that referred to government support for the arts in the U.S. published in five U.S. newspapers between 1986 and 1997—a period during which such assistance, once noncontroversial, became a focus of contention. We illustrate the strengths of topic modeling as a means of analyzing large text corpora, discuss the proper choice of models and interpretation of model results, describe means of validating topic-model solutions, and demonstrate the use of topic models in combination with other statistical tools to estimate differences between newspapers in the prevalence of different frames. Throughout, we emphasize affinities between the topic-modeling approach and such central concepts in the study of culture as framing, polysemy, heteroglossia, and the relationality of meaning.},
	number = {6},
	urldate = {2018-08-28},
	journal = {Poetics},
	author = {DiMaggio, Paul and Nag, Manish and Blei, David},
	month = dec,
	year = {2013},
	note = {Citation Key: DiMaggio2013Exploiting},
	keywords = {Content analysis, Heteroglossia, Meaning, National Endowment for the Arts, Polysemy, Topic models},
	pages = {570--606}
}

@article{Boyd-Graber2017Applications,
	title = {Applications of {Topic} {Models}},
	volume = {11},
	issn = {1554-0669, 1554-0677},
	url = {https://www.nowpublishers.com/article/Details/INR-030},
	doi = {10.1561/1500000030},
	abstract = {Applications of Topic Models},
	language = {English},
	number = {2-3},
	urldate = {2018-08-27},
	journal = {Foundations and Trends® in Information Retrieval},
	author = {Boyd-Graber, Jordan and Hu, Yuening and Mimno, David},
	month = jul,
	year = {2017},
	note = {Citation Key: Boyd-Graber2017Applications},
	pages = {143--296}
}

@book{Cevolini2016Forgetting,
	title = {Forgetting {Machines}: {Knowledge} {Management} {Evolution} in {Early} {Modern} {Europe}},
	isbn = {978-90-04-32525-8},
	shorttitle = {Forgetting {Machines}},
	url = {https://brill.com/view/title/26377},
	language = {en},
	urldate = {2018-08-27},
	publisher = {Brill},
	author = {Cevolini, Alberto},
	month = oct,
	year = {2016},
	note = {Citation Key: Cevolini2016Forgetting}
}

@article{Vedres2010Structural,
	title = {Structural {Folds}: {Generative} {Disruption} in {Overlapping} {Groups}},
	volume = {115},
	issn = {0002-9602},
	shorttitle = {Structural {Folds}},
	url = {http://www.jstor.org/stable/10.1086/649497},
	doi = {10.1086/649497},
	abstract = {Entrepreneurial groups face a twinned challenge: recognizing and implementing new ideas. We argue that entrepreneurship is less about importing ideas than about generating new knowledge by recombining resources. In contrast to the brokerage-plus-closure perspective, we address the overlapping of cohesive group structures. In analyzing the network processes of intercohesion, we identify a distinctive network topology: the structural fold. Actors at the structural fold are multiple insiders, facilitating familiar access to diverse resources. Our data set records personnel ties among the largest 1,696 Hungarian enterprises from 1987 to 2001. First, we test whether structural folding contributes to group performance. Second, because entrepreneurship is a process of generative disruption, we test the contribution of structural folds to group instability. Third, we move from dynamic methods to historical network analysis and demonstrate that coherence is a property of interwoven lineages of cohesion, built up through repeated separation and reunification.},
	number = {4},
	urldate = {2018-06-29},
	journal = {American Journal of Sociology},
	author = {Vedres, Balázs and Stark, David},
	year = {2010},
	note = {bibtex: Vedres2010Structural},
	pages = {1150--1190}
}

@article{Simmel1910How,
	title = {How is {Society} {Possible}?},
	volume = {16},
	issn = {0002-9602},
	url = {http://www.jstor.org/stable/2763090},
	number = {3},
	urldate = {2018-06-29},
	journal = {American Journal of Sociology},
	author = {Simmel, Georg},
	year = {1910},
	note = {bibtex: Simmel1910How},
	pages = {372--391}
}
