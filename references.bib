
@inproceedings{mimno_organizing_2007,
	address = {New York, NY, USA},
	series = {{JCDL} '07},
	title = {Organizing the {OCA}: {Learning} {Faceted} {Subjects} from a {Library} of {Digital} {Books}},
	isbn = {978-1-59593-644-8},
	shorttitle = {Organizing the {OCA}},
	url = {http://doi.acm.org/10.1145/1255175.1255249},
	doi = {10.1145/1255175.1255249},
	abstract = {Large scale library digitization projects such as the Open Content Alliance are producing vast quantities of text, but little has been done to organize this data. Subject headings inherited from card catalogs are useful but limited, while full-text indexing is most appropriate for readers who already know exactly what they want. Statistical topic models provide a complementary function. These models can identify semantically coherent "topics" that are easily recognizable and meaningful to humans, but they have been too computationally intensive to run on library-scale corpora. This paper presents DCM-LDA, a topic model based on Dirichlet Compound Multinomial distributions. This model is simultaneously better able to represent observed properties of text and more scalable to extremely large text collections. We train individual topic models for each book based on the cooccurrence of words within pages. We then cluster topics across books. The resulting topical clusters can be interpreted as subject facets, allowing readers to browse the topics of a collection quickly, find relevant books using topically expanded keyword searches, and explore topical relationships between books. We demonstrate this method finding topics on a corpus of 1.49 billion words from 42,000 books in less than 20 hours, and it easily could scale well beyond this.},
	urldate = {2018-09-10},
	booktitle = {Proceedings of the 7th {ACM}/{IEEE}-{CS} {Joint} {Conference} on {Digital} {Libraries}},
	publisher = {ACM},
	author = {Mimno, David and McCallum, Andrew},
	year = {2007},
	keywords = {classification, topic models},
	pages = {376--385}
}

@inproceedings{hall_studying_2008,
	address = {Stroudsburg, PA, USA},
	series = {{EMNLP} '08},
	title = {Studying the {History} of {Ideas} {Using} {Topic} {Models}},
	url = {http://dl.acm.org/citation.cfm?id=1613715.1613763},
	abstract = {How can the development of ideas in a scientific field be studied over time? We apply unsupervised topic modeling to the ACL Anthology to analyze historical trends in the field of Computational Linguistics from 1978 to 2006. We induce topic clusters using Latent Dirichlet Allocation, and examine the strength of each topic over time. Our methods find trends in the field including the rise of probabilistic methods starting in 1988, a steady increase in applications, and a sharp decline of research in semantics and understanding between 1978 and 2001, possibly rising again after 2001. We also introduce a model of the diversity of ideas, topic entropy, using it to show that COLING is a more diverse conference than ACL, but that both conferences as well as EMNLP are becoming broader over time. Finally, we apply Jensen-Shannon divergence of topic distributions to show that all three conferences are converging in the topics they cover.},
	urldate = {2018-09-10},
	booktitle = {Proceedings of the {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Hall, David and Jurafsky, Daniel and Manning, Christopher D.},
	year = {2008},
	pages = {363--371}
}

@article{blei_correlated_2007,
	title = {A correlated topic model of {Science}},
	volume = {1},
	issn = {1932-6157},
	url = {http://arxiv.org/abs/0708.3601},
	doi = {10.1214/07-AOAS114},
	abstract = {Topic models, such as latent Dirichlet allocation (LDA), can be useful tools for the statistical analysis of document collections and other discrete data. The LDA model assumes that the words of each document arise from a mixture of topics, each of which is a distribution over the vocabulary. A limitation of LDA is the inability to model topic correlation even though, for example, a document about genetics is more likely to also be about disease than X-ray astronomy. This limitation stems from the use of the Dirichlet distribution to model the variability among the topic proportions. In this paper we develop the correlated topic model (CTM), where the topic proportions exhibit correlation via the logistic normal distribution [J. Roy. Statist. Soc. Ser. B 44 (1982) 139--177]. We derive a fast variational inference algorithm for approximate posterior inference in this model, which is complicated by the fact that the logistic normal is not conjugate to the multinomial. We apply the CTM to the articles from Science published from 1990--1999, a data set that comprises 57M words. The CTM gives a better fit of the data than LDA, and we demonstrate its use as an exploratory tool of large document collections.},
	number = {1},
	urldate = {2018-09-10},
	journal = {The Annals of Applied Statistics},
	author = {Blei, David M. and Lafferty, John D.},
	month = jun,
	year = {2007},
	note = {arXiv: 0708.3601},
	keywords = {Statistics - Applications},
	pages = {17--35}
}

@inproceedings{newman_analyzing_2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Analyzing {Entities} and {Topics} in {News} {Articles} {Using} {Statistical} {Topic} {Models}},
	isbn = {978-3-540-34479-7},
	abstract = {Statistical language models can learn relationships between topics discussed in a document collection and persons, organizations and places mentioned in each document. We present a novel combination of statistical topic models and named-entity recognizers to jointly analyze entities mentioned (persons, organizations and places) and topics discussed in a collection of 330,000 New York Times news articles. We demonstrate an analytic framework which automatically extracts from a large collection: topics; topic trends; and topics that relate entities.},
	language = {en},
	booktitle = {Intelligence and {Security} {Informatics}},
	publisher = {Springer Berlin Heidelberg},
	author = {Newman, David and Chemudugunta, Chaitanya and Smyth, Padhraic and Steyvers, Mark},
	editor = {Mehrotra, Sharad and Zeng, Daniel D. and Chen, Hsinchun and Thuraisingham, Bhavani and Wang, Fei-Yue},
	year = {2006},
	keywords = {Latent Dirichlet Allocation, Latent Semantic Analysis, Latent Semantic Indexing, News Article, Topic Model},
	pages = {93--104}
}

@incollection{Grimmer2016Measuring,
	address = {New York, NY},
	edition = {Reprint edition},
	series = {Analytical {Methods} for {Social} {Research}},
	title = {Measuring {Representational} {Style} in the {House}: {The} {Tea} {Party}, {Obama}, and {Legislators}â€™ {Changing} {Expressed} {Priorities}},
	isbn = {978-1-107-51841-4},
	url = {https://www.cambridge.org/core/books/computational-social-science/measuring-representational-style-in-the-house-the-tea-party-obama-and-legislators-changing-expressed-priorities/F796451CE2D672F7479498CF82ADEA54},
	abstract = {Quantitative research in social science research is changing rapidly. Researchers have vast and complex arrays of data with which to work: we have incredible tools to sift through the data and recognize patterns in that data; there are now many sophisticated models that we can use to make sense of those patterns; and we have extremely powerful computational systems that help us accomplish these tasks quickly. This book focuses on some of the extraordinary work being conducted in computational social science - in academia, government, and the private sector - while highlighting current trends, challenges, and new directions. Thus, Computational Social Science showcases the innovative methodological tools being developed and applied by leading researchers in this new field. The book shows how academics and the private sector are using many of these tools to solve problems in social science and public policy.},
	language = {English},
	urldate = {2016-09-22},
	booktitle = {Computational {Social} {Science}: {Discovery} and {Prediction}},
	publisher = {Cambridge University Press},
	author = {Grimmer, Justin},
	editor = {Alvarez, R. Michael},
	month = mar,
	year = {2016},
	note = {Citation Key: Grimmer2016Measuring},
	pages = {225--245}
}

@book{JOCKERS2013Macroanalysis,
	title = {Macroanalysis: {Digital} {Methods} and {Literary} {History}},
	isbn = {978-0-252-03752-8},
	shorttitle = {Macroanalysis},
	url = {https://www.jstor.org/stable/10.5406/j.ctt2jcc3m},
	abstract = {In this volume, Matthew L. Jockers introduces readers to large-scale literary computing and the revolutionary potential of macroanalysis--a new approach to the study of the literary record designed for probing the digital-textual world as it exists today, in digital form and in large quantities. Using computational analysis to retrieve key words, phrases, and linguistic patterns across thousands of texts in digital libraries, researchers can draw conclusions based on quantifiable evidence regarding how literary trends are employed over time, across periods, within regions, or within demographic groups, as well as how cultural, historical, and societal linkages may bind individual authors, texts, and genres into an aggregate literary culture. Moving beyond the limitations of literary interpretation based on the close-reading of individual works, Jockers describes how this new method of studying large collections of digital material can help us to better understand and contextualize the individual works within those collections.},
	urldate = {2018-09-06},
	publisher = {University of Illinois Press},
	author = {JOCKERS, MATTHEW L.},
	year = {2013},
	note = {Citation Key: JOCKERS2013Macroanalysis}
}

@book{Luhmann2002Theories,
	title = {Theories of {Distinction}: {Redescribing} the {Descriptions} of {Modernity}},
	isbn = {978-0-8047-4123-1},
	shorttitle = {Theories of {Distinction}},
	abstract = {The essays in this volume by Germany\&\#39;s leading social theorist of the late twentieth century formulate what he considered to be the preconditions for an adequate theory of modern society.  The first two essays deal with the modern European philosophical and scientific tradition, notably the ogy of Edmund Husserl. The next four essays concern the crucial notion of observation as defined by Luhmann. They examine the history of paradox as a logical problem and as a historically conditioned feature of rhetoric; deconstruct the thinking of Jacques Derrida, especially his language-centered allegiances; discuss the usefulness of Spencer Brown\&\#39;s Laws of Form; and assess the consequences of observation and paradox for epistemology.  The following essays present Luhmann\&\#39;s theory of communication and his articulation of the difference between thought and communication, a difference that makes clear one of Luhmann\&\#39;s most radical and controversial theses, that the individual not only does not form the basic element of society but is excluded from it altogether, situated instead in the environment of the social system. The book concludes with a polemic against the critical thought of the Frankfurt School of postwar German social thought.},
	language = {en},
	publisher = {Stanford University Press},
	author = {Luhmann, Niklas and Rasch, William},
	year = {2002},
	note = {Google-Books-ID: L0G2bwV9VMMC
Citation Key: Luhmann2002Theories},
	keywords = {Social Science / Sociology / General}
}

@article{DiMaggio2013Exploiting,
	series = {Topic {Models} and the {Cultural} {Sciences}},
	title = {Exploiting affinities between topic modeling and the sociological perspective on culture: {Application} to newspaper coverage of {U}.{S}. government arts funding},
	volume = {41},
	issn = {0304-422X},
	shorttitle = {Exploiting affinities between topic modeling and the sociological perspective on culture},
	url = {http://www.sciencedirect.com/science/article/pii/S0304422X13000661},
	doi = {10.1016/j.poetic.2013.08.004},
	abstract = {Topic modeling provides a valuable method for identifying the linguistic contexts that surround social institutions or policy domains. This article uses Latent Dirichlet Allocation (LDA) to analyze how one such policy domain, government assistance to artists and arts organizations, was framed in almost 8000 articles. These comprised all articles that referred to government support for the arts in the U.S. published in five U.S. newspapers between 1986 and 1997â€”a period during which such assistance, once noncontroversial, became a focus of contention. We illustrate the strengths of topic modeling as a means of analyzing large text corpora, discuss the proper choice of models and interpretation of model results, describe means of validating topic-model solutions, and demonstrate the use of topic models in combination with other statistical tools to estimate differences between newspapers in the prevalence of different frames. Throughout, we emphasize affinities between the topic-modeling approach and such central concepts in the study of culture as framing, polysemy, heteroglossia, and the relationality of meaning.},
	number = {6},
	urldate = {2018-08-28},
	journal = {Poetics},
	author = {DiMaggio, Paul and Nag, Manish and Blei, David},
	month = dec,
	year = {2013},
	note = {Citation Key: DiMaggio2013Exploiting},
	keywords = {Content analysis, Heteroglossia, Meaning, National Endowment for the Arts, Polysemy, Topic models},
	pages = {570--606}
}

@article{Boyd-Graber2017Applications,
	title = {Applications of {Topic} {Models}},
	volume = {11},
	issn = {1554-0669, 1554-0677},
	url = {https://www.nowpublishers.com/article/Details/INR-030},
	doi = {10.1561/1500000030},
	abstract = {Applications of Topic Models},
	language = {English},
	number = {2-3},
	urldate = {2018-08-27},
	journal = {Foundations and TrendsÂ® in Information Retrieval},
	author = {Boyd-Graber, Jordan and Hu, Yuening and Mimno, David},
	month = jul,
	year = {2017},
	note = {Citation Key: Boyd-Graber2017Applications},
	pages = {143--296}
}

@book{Cevolini2016Forgetting,
	title = {Forgetting {Machines}: {Knowledge} {Management} {Evolution} in {Early} {Modern} {Europe}},
	isbn = {978-90-04-32525-8},
	shorttitle = {Forgetting {Machines}},
	url = {https://brill.com/view/title/26377},
	language = {en},
	urldate = {2018-08-27},
	publisher = {Brill},
	author = {Cevolini, Alberto},
	month = oct,
	year = {2016},
	note = {Citation Key: Cevolini2016Forgetting}
}

@article{Vedres2010Structural,
	title = {Structural {Folds}: {Generative} {Disruption} in {Overlapping} {Groups}},
	volume = {115},
	issn = {0002-9602},
	shorttitle = {Structural {Folds}},
	url = {http://www.jstor.org/stable/10.1086/649497},
	doi = {10.1086/649497},
	abstract = {Entrepreneurial groups face a twinned challenge: recognizing and implementing new ideas. We argue that entrepreneurship is less about importing ideas than about generating new knowledge by recombining resources. In contrast to the brokerage-plus-closure perspective, we address the overlapping of cohesive group structures. In analyzing the network processes of intercohesion, we identify a distinctive network topology: the structural fold. Actors at the structural fold are multiple insiders, facilitating familiar access to diverse resources. Our data set records personnel ties among the largest 1,696 Hungarian enterprises from 1987 to 2001. First, we test whether structural folding contributes to group performance. Second, because entrepreneurship is a process of generative disruption, we test the contribution of structural folds to group instability. Third, we move from dynamic methods to historical network analysis and demonstrate that coherence is a property of interwoven lineages of cohesion, built up through repeated separation and reunification.},
	number = {4},
	urldate = {2018-06-29},
	journal = {American Journal of Sociology},
	author = {Vedres, BalÃ¡zs and Stark, David},
	year = {2010},
	note = {bibtex: Vedres2010Structural},
	pages = {1150--1190}
}

@article{Simmel1910How,
	title = {How is {Society} {Possible}?},
	volume = {16},
	issn = {0002-9602},
	url = {http://www.jstor.org/stable/2763090},
	number = {3},
	urldate = {2018-06-29},
	journal = {American Journal of Sociology},
	author = {Simmel, Georg},
	year = {1910},
	note = {bibtex: Simmel1910How},
	pages = {372--391}
}
